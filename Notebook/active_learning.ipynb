{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf9dd64",
   "metadata": {},
   "source": [
    "# Fonctions d'acquisition pour l'apprentissage actif sur des images de déchets\n",
    "\n",
    "Ce notebook présente et implémente différentes fonctions d'acquisition utilisées dans le cadre de l'apprentissage actif pour la classification d'images de déchets. Les fonctions d'acquisition permettent de sélectionner les échantillons les plus informatifs à annoter, afin d'améliorer l'efficacité de l'entraînement du modèle tout en réduisant le nombre d'annotations nécessaires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8de01",
   "metadata": {},
   "source": [
    "## 1. Définir les fonctions d'acquisition\n",
    "\n",
    "Les fonctions d'acquisition jouent un rôle central dans l'apprentissage actif. Elles permettent de mesurer l'incertitude du modèle sur les données non annotées et de sélectionner les exemples les plus pertinents à ajouter au jeu d'entraînement.\n",
    "\n",
    "Dans ce notebook, nous allons implémenter les fonctions d'acquisition suivantes :\n",
    "- **Max Entropy** : sélectionne les échantillons ayant la plus grande entropie prédictive.\n",
    "- **BALD** (Bayesian Active Learning by Disagreement) : sélectionne les échantillons maximisant l'information mutuelle entre les prédictions et les paramètres du modèle.\n",
    "- **Mean STD** : sélectionne les échantillons ayant la plus grande variance moyenne des prédictions.\n",
    "- **Variational Ratios** : sélectionne les échantillons pour lesquels le modèle a le moins de confiance (plus grande incertitude)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5415a",
   "metadata": {},
   "source": [
    "## 2. Implémenter la fonction de prédiction sur le pool\n",
    "\n",
    "Pour toutes les fonctions d'acquisition, il est nécessaire d'obtenir des prédictions du modèle sur un sous-ensemble aléatoire du pool d'images. On utilise le MC Dropout pour obtenir une distribution de sorties, ce qui permet d'estimer l'incertitude du modèle.\n",
    "\n",
    "La fonction suivante effectue plusieurs passes stochastiques sur le modèle pour chaque échantillon du pool et retourne les probabilités prédites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b57149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def predictions_from_pool(\n",
    "    model, \n",
    "    X_pool: np.ndarray, \n",
    "    T: int = 100, \n",
    "    training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Effectue des prédictions sur un sous-ensemble aléatoire du pool à l'aide du modèle,\n",
    "    en utilisant MC Dropout pour obtenir des distributions de sortie.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné (doit supporter le mode dropout).\n",
    "        X_pool: Ensemble de données (pool) sous forme de tableau numpy.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        training: Si True, active le mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        outputs: Tableau numpy de forme (T, N_subset, C) contenant les probabilités.\n",
    "        random_subset: Indices sélectionnés dans le pool.\n",
    "    \"\"\"\n",
    "    subset_size = min(500, len(X_pool))\n",
    "    random_subset = np.random.choice(range(len(X_pool)), size=subset_size, replace=False)\n",
    "    with torch.no_grad():\n",
    "        outputs = np.stack(\n",
    "            [\n",
    "                torch.softmax(\n",
    "                    model.estimator.forward(X_pool[random_subset], training=training),\n",
    "                    dim=-1,\n",
    "                )\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "                for _ in range(T)\n",
    "            ]\n",
    "        )\n",
    "    return outputs, random_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421928c",
   "metadata": {},
   "source": [
    "## 3. Fonction d'entropie de Shannon\n",
    "\n",
    "L'entropie de Shannon mesure l'incertitude globale des prédictions du modèle pour chaque échantillon. Plus l'entropie est élevée, plus le modèle est incertain.\n",
    "\n",
    "La fonction suivante calcule l'entropie de Shannon à partir des prédictions obtenues via MC Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0114311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shannon_entropy_function(\n",
    "    model, \n",
    "    X_pool: np.ndarray, \n",
    "    T: int = 100, \n",
    "    E_H: bool = False, \n",
    "    training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Calcule l'entropie de Shannon sur les prédictions du modèle pour mesurer l'incertitude.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné.\n",
    "        X_pool: Pool d'échantillons.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        E_H: Si True, retourne aussi l'entropie attendue pour BALD.\n",
    "        training: Mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        H: Entropie de Shannon pour chaque échantillon.\n",
    "        E (optionnel): Entropie attendue (pour BALD).\n",
    "        random_subset: Indices sélectionnés dans le pool.\n",
    "    \"\"\"\n",
    "    outputs, random_subset = predictions_from_pool(model, X_pool, T, training=training)\n",
    "    pc = outputs.mean(axis=0)\n",
    "    H = (-pc * np.log(pc + 1e-10)).sum(axis=-1) # Pour éviter log(0)\n",
    "    if E_H:\n",
    "        E = -np.mean(np.sum(outputs * np.log(outputs + 1e-10), axis=-1), axis=0)\n",
    "        return H, E, random_subset\n",
    "    return H, random_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00812475",
   "metadata": {},
   "source": [
    "## 4. Fonction Max Entropy\n",
    "\n",
    "La stratégie Max Entropy sélectionne les échantillons du pool pour lesquels l'entropie prédictive est maximale, c'est-à-dire ceux pour lesquels le modèle est le plus incertain.\n",
    "\n",
    "Voici l'implémentation de cette fonction d'acquisition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9142a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_entropy(\n",
    "    model, X_pool: np.ndarray, n_query: int = 10, T: int = 100, training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Sélectionne les points du pool qui maximisent l'entropie prédictive.\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné.\n",
    "        X_pool: Pool d'échantillons.\n",
    "        n_query: Nombre d'échantillons à sélectionner.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        training: Mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        query_idx: Indices des échantillons sélectionnés dans le pool.\n",
    "        X_pool[query_idx]: Données correspondantes.\n",
    "    \"\"\"\n",
    "    acquisition, random_subset = shannon_entropy_function(\n",
    "        model, X_pool, T, training=training\n",
    "    )\n",
    "    idx = (-acquisition).argsort()[:n_query]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528332d0",
   "metadata": {},
   "source": [
    "## 5. Fonction Mean STD Acquisition\n",
    "\n",
    "La stratégie Mean STD sélectionne les échantillons pour lesquels la variance moyenne des prédictions (sur les classes) est la plus élevée, ce qui indique une forte incertitude du modèle.\n",
    "\n",
    "Voici l'implémentation de cette fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330de30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_acquisition(\n",
    "    model, \n",
    "    X_pool: np.ndarray, \n",
    "    n_query: int = 10, \n",
    "    T: int = 100, \n",
    "    training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Sélectionne les points du pool qui maximisent l'écart-type moyen des prédictions (Mean STD).\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné.\n",
    "        X_pool: Pool d'échantillons.\n",
    "        n_query: Nombre d'échantillons à sélectionner.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        training: Mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        query_idx: Indices des échantillons sélectionnés dans le pool.\n",
    "        X_pool[query_idx]: Données correspondantes.\n",
    "    \"\"\"\n",
    "    outputs, random_subset = predictions_from_pool(model, X_pool, T, training=training)\n",
    "    expected_p_c = np.mean(outputs, axis=0)\n",
    "    expected_p_c_squared = np.mean(outputs**2, axis=0)\n",
    "    sigma_c = expected_p_c_squared - (expected_p_c**2)\n",
    "    acquisition_scores = np.mean(sigma_c, axis=-1)\n",
    "    idx = (-acquisition_scores).argsort()[:n_query]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5217b",
   "metadata": {},
   "source": [
    "## 6. Fonction BALD\n",
    "\n",
    "La stratégie BALD (Bayesian Active Learning by Disagreement) sélectionne les échantillons qui maximisent l'information mutuelle entre les prédictions et les paramètres du modèle. Cela permet de cibler les exemples pour lesquels le modèle est incertain en moyenne, mais où il existe une forte désaccord entre différentes passes du modèle.\n",
    "\n",
    "Voici l'implémentation de la fonction BALD :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fd6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bald(\n",
    "    model, X_pool: np.ndarray, n_query: int = 10, T: int = 100, training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Sélectionne les points du pool qui maximisent l'information mutuelle (BALD).\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné.\n",
    "        X_pool: Pool d'échantillons.\n",
    "        n_query: Nombre d'échantillons à sélectionner.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        training: Mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        query_idx: Indices des échantillons sélectionnés dans le pool.\n",
    "        X_pool[query_idx]: Données correspondantes.\n",
    "    \"\"\"\n",
    "    H, E_H, random_subset = shannon_entropy_function(\n",
    "        model, X_pool, T, E_H=True, training=training\n",
    "    )\n",
    "    acquisition = H - E_H\n",
    "    idx = (-acquisition).argsort()[:n_query]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b9c042",
   "metadata": {},
   "source": [
    "## 7. Fonction Variational Ratios\n",
    "\n",
    "La stratégie Variational Ratios mesure le manque de confiance du modèle en sélectionnant les échantillons pour lesquels la classe prédite la plus fréquente a la plus faible proportion parmi les passes MC Dropout.\n",
    "\n",
    "Voici l'implémentation de cette fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4215d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def var_ratios(\n",
    "    model, X_pool: np.ndarray, n_query: int = 10, T: int = 100, training: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Sélectionne les points du pool pour lesquels le modèle a le moins de confiance (Variational Ratios).\n",
    "\n",
    "    Args:\n",
    "        model: Modèle entraîné.\n",
    "        X_pool: Pool d'échantillons.\n",
    "        n_query: Nombre d'échantillons à sélectionner.\n",
    "        T: Nombre d'itérations MC Dropout.\n",
    "        training: Mode entraînement (dropout activé).\n",
    "\n",
    "    Returns:\n",
    "        query_idx: Indices des échantillons sélectionnés dans le pool.\n",
    "        X_pool[query_idx]: Données correspondantes.\n",
    "    \"\"\"\n",
    "    outputs, random_subset = predictions_from_pool(model, X_pool, T, training)\n",
    "    preds = np.argmax(outputs, axis=2)\n",
    "    _, count = stats.mode(preds, axis=0)\n",
    "    acquisition = (1 - count / preds.shape[1]).reshape((-1,))\n",
    "    idx = (-acquisition).argsort()[:n_query]\n",
    "    query_idx = random_subset[idx]\n",
    "    return query_idx, X_pool[query_idx]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
